{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "igEd7obtcxR2"
   },
   "source": [
    "## Approach\n",
    "\n",
    "* This is a simplied version of YOLO. The input image is 512x512. YOLO was intended to train on images which all contained at least one object, most multiple objects. The architecture and loss functions have been adapted for this case, where not every image contains an object and there are at most 4 ROIs per image. \n",
    "* Since the maximum number of ROIs in each image is 4 we decided to use a 2x2 grid to simplify the network. In the case where multiple ROIs occur in the same cell we combine the ROIs into a single ROI by expanding the box to include both. Each cell outputs five values:\n",
    "    * The confidence that there is pneumonia present\n",
    "    * The x, y, w, and h of the bounding box\n",
    "    * We have removed the entire classification section, using the confidence to indicate whether there is an ROI in the cell instead.\n",
    "* A sigmoid is applied to the output of the network to result in values between 0 and 1    \n",
    "* The x and y coordinates are offsets from the upper left corner of each cell, the w and h are percentage of the total width.\n",
    "* The loss function is based on YOLO with some differences:\n",
    "    * The weights of the components have been updated\n",
    "    * The classification loss has been removed.\n",
    "    * The \"objectness\" loss of YOLO tries to make the confidence match the actual IOU. Since our model only outputs one box per cell, this doesn't really make any sense and ends up driving the confidence down to the IOU. We replace this by an IOU loss which subtracts the IOU for that cell from 1.\n",
    "\n",
    "## Network\n",
    "\n",
    "* The network consists of a number of residual blocks with convolutions and downsampling blocks with max pooling.\n",
    "* There are two dilated convolutions at the end of the network to provide context.\n",
    "* The dilated convolutions are followed by two strided convolutions which downsize to 2x2.\n",
    "* Finally there are a series of 1x1 convolutions which output a 2x2x5 tensor.\n",
    "* We are using an Adam optimizer with gradient clipping to avoid exploding gradients, which had been a problem.\n",
    "\n",
    "## Predictions\n",
    "* To generate our predictions we loop through each cell of the output\n",
    "* We unnormalize the output to get the actual values\n",
    "* If the confidence is greater than 0.5 and the box has width and height we append it to the list of candidates.\n",
    "* We apply non-max suppression to remove duplicates.\n",
    "* The remaining boxes are concatenated onto the output string.\n",
    "\n",
    "**Change Log:**\n",
    "* v3 - changing output to 8x8 grid from 16x16; changed model to downsample one more time; adjusted network accordingly. \n",
    "* v4 - changed output to 4x4 grid, no image has more than 3 ROIs so this may work better? \n",
    "    * Using center point of ROI to predict instead of upper left corner.\n",
    "* v5 - We only calculate MSE loss for boxes with a confidence over 0.5 or actual truth since we don't care about predictions for boxes that are not ROIs. This will prevent the network from being constrained by outputting 0s for boxes that don't exist.\n",
    "* v6 - centering input data so maybe bboxes can be output more accurately? Also centering the image\n",
    "* v6.2 - labels have ROI centered in center of cell by default instead of mean location.\n",
    "* v8 - using custom loss function based on YOLO loss. Set default height and width to 1 px because 0 sent the gradients to -inf which screwed everything up.\n",
    "* v10 - using 2x2 grid as output\n",
    "* v12 - changing layout of model slightly - replaced final pools with convs with strides; reduced number of params; ensure that there is at least one positive image per batch.\n",
    "* v13 - tweaking architecture slightly.\n",
    "* v14 - going to 5x5 grid\n",
    "* v15 - downsizing with average and max pool followed by 1x1 convolutions\n",
    "* v15.2 - fixed an error where a layer of the network was being bypassed, removed some layers to prevent overfitting, training on labels with jittered ROIs\n",
    "* v18 - separating fc branches for confidence and boxes, might work better?\n",
    "* v19 - removing double pools and just using a simple max pool\n",
    "* v20 - adding more layers to network, simplifying metrics and loss function\n",
    "* v21 - trying 7x7 grid, removing one downsampling layer to keep input size reasonable\n",
    "* v22 - some minor changes to network\n",
    "* v23 - adding spatial dropout to prevent overfitting, other minor changes\n",
    "* v24 - separating augmentation into discrete levels so we can slowly add it to speed up training, minor changes to network\n",
    "* v25 - removed IOU component of loss function which was royally screwing everything up, removed some layers of network to prevent overtfitting\n",
    "* v26 - adding some layers back, training from scratch with better weighted loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHncOor-cxSS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import gaussian\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQ34pL62UyT4"
   },
   "outputs": [],
   "source": [
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh=0.3):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    " \n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    " \n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    " \n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    w = boxes[:,2]\n",
    "    h = boxes[:,3]\n",
    " \n",
    "    x2 = x1 + w\n",
    "    y2 = y1 + h\n",
    "\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (w + 1) * (h + 1)\n",
    "    idxs = np.argsort(y2)\n",
    " \n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    " \n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    " \n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    " \n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    " \n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    " \n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick]#.astype(\"int\")\n",
    "\n",
    "# get actual x and y values from sigmoid output and what cell they are in\n",
    "def unnorm(val, idx, cell_size=256):\n",
    "    x = (val * cell_size) + (cell_size * idx)\n",
    "    return x\n",
    "\n",
    "# sigmoid in numpy, with limit to avoid nans                             \n",
    "def sigmoid(x):\n",
    "    # to avoid NaNs set a lower floor on x values\n",
    "    y = np.maximum(x, -700)\n",
    "    y = np.minimum(y, 700)\n",
    "    return 1 / (1 + np.exp(-y))    \n",
    "\n",
    "# adjust contrast of image\n",
    "def change_contrast(img, contrast_factor):\n",
    "    mean = np.mean(img)\n",
    "    img = (img - mean) * contrast_factor + mean\n",
    "    return img\n",
    "\n",
    "def get_intersect(box1, box2):\n",
    "    # unpack each box\n",
    "    x1, y1, w1, h1, c1 = box1\n",
    "    x2, y2, w2, h2, x2 = box2\n",
    "    \n",
    "    # get the far corners\n",
    "    x1_f = x1 + w1\n",
    "    y1_f = y1 + h1\n",
    "    x2_f = x2 + w2\n",
    "    y2_f = y2 + h2\n",
    "    \n",
    "    # get corners of intersection\n",
    "    x1_i = np.maximum(x1, x2)\n",
    "    y1_i = np.maximum(y1, y2)\n",
    "    x2_i = np.minimum(x1_f, x2_f)\n",
    "    y2_i = np.minimum(y1_f, y2_f)\n",
    "    \n",
    "    w_i = x2_i - x1_i\n",
    "    h_i = y2_i - y1_i\n",
    "    \n",
    "    w_i = np.maximum(w_i, 0)\n",
    "    h_i = np.maximum(h_i, 0)\n",
    "\n",
    "    intersect_area = w_i * h_i\n",
    "    \n",
    "    return intersect_area  \n",
    "  \n",
    "# helper function to calculate IoU\n",
    "def calculate_iou(box1, box2):\n",
    "    x11, y11, w1, h1 = box1[:4]\n",
    "    x21, y21, w2, h2 = box2[:4]\n",
    "    assert w1 * h1 > 0\n",
    "    assert w2 * h2 > 0\n",
    "    x12, y12 = x11 + w1, y11 + h1\n",
    "    x22, y22 = x21 + w2, y21 + h2\n",
    "\n",
    "    area1, area2 = w1 * h1, w2 * h2\n",
    "    xi1, yi1, xi2, yi2 = max([x11, x21]), max([y11, y21]), min([x12, x22]), min([y12, y22])\n",
    "    \n",
    "    if xi2 <= xi1 or yi2 <= yi1:\n",
    "        return 0\n",
    "    else:\n",
    "        intersect = (xi2-xi1) * (yi2-yi1)\n",
    "        union = area1 + area2 - intersect\n",
    "        return intersect / union  \n",
    "\n",
    "# calculate IOU where there can be multiple overlapping truths and predictions\n",
    "def calc_iou_better(y_true, y_pred):\n",
    "    label_array = np.zeros((1024, 1024))\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    for truth in y_true:\n",
    "        x,y,w,h = truth[:4].astype(int)  \n",
    "        label_array[y:y+h, x:x+w] = 1\n",
    "                \n",
    "    pred_array = np.zeros((1024, 1024))\n",
    "    for pred in y_pred:\n",
    "        x,y,w,h = pred[:4].astype(int)\n",
    "\n",
    "        # update the pixels\n",
    "        pred_array[y:y+h, x:x+w] = 1\n",
    "                \n",
    "    true_area = np.sum(label_array)\n",
    "    pred_area = np.sum(pred_array)\n",
    "    \n",
    "    intersect_area = np.sum((pred_array == 1) & (label_array == 1))\n",
    "    \n",
    "    union = true_area + pred_area - intersect_area\n",
    "    \n",
    "    iou = intersect_area / (union + 1e-6)\n",
    "    \n",
    "    return iou      \n",
    "      \n",
    "def map_iou(boxes_true, boxes_pred, scores, thresholds = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]):\n",
    "    \"\"\"\n",
    "    Mean average precision at differnet intersection over union (IoU) threshold\n",
    "    \n",
    "    input:\n",
    "        boxes_true: Mx4 numpy array of ground true bounding boxes of one image. \n",
    "                    bbox format: (x1, y1, w, h)\n",
    "        boxes_pred: Nx4 numpy array of predicted bounding boxes of one image. \n",
    "                    bbox format: (x1, y1, w, h)\n",
    "        scores:     length N numpy array of scores associated with predicted bboxes\n",
    "        thresholds: IoU shresholds to evaluate mean average precision on\n",
    "    output: \n",
    "        map: mean average precision of the image\n",
    "    \"\"\"\n",
    "    \n",
    "    # According to the introduction, images with no ground truth bboxes will not be \n",
    "    # included in the map score unless there is a false positive detection (?)\n",
    "        \n",
    "    # return None if both are empty, don't count the image in final evaluation (?)\n",
    "    if len(boxes_true) == 0 and len(boxes_pred) == 0:\n",
    "        return None\n",
    "    elif (len(boxes_true) == 0) and (len(boxes_pred) != 0):\n",
    "        return 0\n",
    "    \n",
    "    assert boxes_true.shape[1] == 4 or boxes_pred.shape[1] == 4, \"boxes should be 2D arrays with shape[1]=4\"\n",
    "    if len(boxes_pred):\n",
    "        assert len(scores) == len(boxes_pred), \"boxes_pred and scores should be same length\"\n",
    "        # sort boxes_pred by scores in decreasing order\n",
    "        boxes_pred = boxes_pred[np.argsort(scores)[::-1], :]\n",
    "    \n",
    "    map_total = 0\n",
    "    \n",
    "    # loop over thresholds\n",
    "    for t in thresholds:\n",
    "        matched_bt = set()\n",
    "        tp, fn = 0, 0\n",
    "        for i, bt in enumerate(boxes_true):\n",
    "            matched = False\n",
    "            for j, bp in enumerate(boxes_pred):\n",
    "                miou = calculate_iou(bt, bp)\n",
    "                if miou >= t and not matched and j not in matched_bt:\n",
    "                    matched = True\n",
    "                    tp += 1 # bt is matched for the first time, count as TP\n",
    "                    matched_bt.add(j)\n",
    "            if not matched:\n",
    "                fn += 1 # bt has no match, count as FN\n",
    "                \n",
    "        fp = len(boxes_pred) - len(matched_bt) # FP is the bp that not matched to any bt\n",
    "        m = tp / (tp + fn + fp)\n",
    "        map_total += m\n",
    "    \n",
    "    return map_total / len(thresholds)      \n",
    "\n",
    "# given the label or predictions, return a list containing the actual coordinates\n",
    "# for each box\n",
    "def unnorm_label(label, threshold=0.5):\n",
    "    grid_size = label.shape[0]\n",
    "    cell_size = 1024 / grid_size\n",
    "    \n",
    "    boxes = []\n",
    "    # loop through the cells of our label\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            # if we have a box in a cell\n",
    "            if label[i,j,0] > threshold:\n",
    "                # unpack the data\n",
    "                c, x, y, w, h = label[i, j]\n",
    "                \n",
    "                # unnormalize the data\n",
    "                w, h = int(w*1024), int(h*1024)\n",
    "                x = unnorm(x, j, cell_size)\n",
    "                y = unnorm(y, i, cell_size)\n",
    "                \n",
    "                # get the corners\n",
    "                x = int(x - (w / 2))\n",
    "                y = int(y - (h / 2))\n",
    "                \n",
    "                # it's possible the corner is in another cell, if so catch the error\n",
    "                x = np.maximum(x, 0)\n",
    "                y = np.maximum(y, 0)\n",
    "                    \n",
    "#                 print(x, y, w, h, \"box:\", i, j)\n",
    "                boxes.append([x, y, w, h, c])\n",
    "    \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hE3jDmgudDDP"
   },
   "outputs": [],
   "source": [
    "# enter your Kaggle credentionals here\n",
    "os.environ['KAGGLE_USERNAME']=\"skooch\"\n",
    "os.environ['KAGGLE_KEY']=\"42f8a02ee92cc773d1dbe66565673ad3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSWY-U2TcxSn"
   },
   "source": [
    "# Load pneumonia locations\n",
    "\n",
    "Table contains [filename : pneumonia location] pairs per row. \n",
    "* If a filename contains multiple pneumonia, the table contains multiple rows with the same filename but different pneumonia locations. \n",
    "* If a filename contains no pneumonia it contains a single row with an empty pneumonia location.\n",
    "\n",
    "The code below loads the table and transforms it into a dictionary. \n",
    "* The dictionary uses the filename as key and a list of pneumonia locations in that filename as value. \n",
    "* If a filename is not present in the dictionary it means that it contains no pneumonia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "m_0ZGQyLdQS8",
    "outputId": "75895cc6-6497-42c0-f081-47a464083aee"
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"./\"\n",
    "\n",
    "train_dicom_dir = os.path.join(ROOT_DIR, 'stage_1_train_images')\n",
    "test_dicom_dir = os.path.join(ROOT_DIR, 'stage_1_test_images')\n",
    "print(\"Train dir:\", train_dicom_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hopsRmICcxSs"
   },
   "outputs": [],
   "source": [
    "with open('yolo_labels_centered_7x7_11b_2.p', 'rb') as handle:\n",
    "    pneumonia_locations = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UoB6GBhIcxS6"
   },
   "source": [
    "# Load filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "b_iB-IftcxTE",
    "outputId": "72ca2655-6846-4ca2-e3c2-f0800a38c482"
   },
   "outputs": [],
   "source": [
    "random.seed(217)\n",
    "\n",
    "# load and shuffle filenames\n",
    "folder = './stage_1_train_images'\n",
    "filenames = os.listdir(folder)\n",
    "random.shuffle(filenames)\n",
    "# split into train and validation filenames\n",
    "n_valid_samples = int(len(filenames) * 0.12)\n",
    "train_filenames = filenames[n_valid_samples:]\n",
    "valid_filenames = filenames[:n_valid_samples]\n",
    "print('n train samples', len(train_filenames))\n",
    "print('n valid samples', len(valid_filenames))\n",
    "n_train_samples = len(filenames) - n_valid_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9qMFILJUyUR"
   },
   "outputs": [],
   "source": [
    "positive_images = []\n",
    "\n",
    "for filename in pneumonia_locations:\n",
    "    label = pneumonia_locations[filename][...,0]\n",
    "    if np.max(label) > 1e-6:\n",
    "        if filename + \".dcm\" in train_filenames:\n",
    "            positive_images.append(filename + \".dcm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lorV7ZmDcxTa"
   },
   "source": [
    " # Data generator\n",
    "\n",
    "The dataset is too large to fit into memory, so we need to create a generator that loads data on the fly.\n",
    "\n",
    "* The generator takes in some filenames, batch_size and other parameters.\n",
    "\n",
    "* The generator outputs a random batch of numpy images and numpy masks.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFbLdFxVehhB"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "IMAGE_SIZE = 336\n",
    "GRID_SIZE = 7\n",
    "CELL_SIZE = 1024 / GRID_SIZE\n",
    "CHECKPOINT_PATH = \"yolo26_1_336.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TueY1bVlcxTg"
   },
   "outputs": [],
   "source": [
    "class generator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, folder, filenames, pneumonia_locations=None, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=0, predict=False):\n",
    "        self.folder = folder\n",
    "        self.filenames = filenames\n",
    "        self.pneumonia_locations = pneumonia_locations\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.predict = predict\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def augment_imgs(self, img, confs, boxes):\n",
    "        ## always do these augmentations\n",
    "        # flip the image half the time\n",
    "        if random.random() > 0.5:\n",
    "            img = np.fliplr(img)\n",
    "            \n",
    "            # update our x coords\n",
    "            mask = (confs != 0)\n",
    "            \n",
    "            # flip\n",
    "            boxes[mask, 0] = (1 - boxes[mask,0])\n",
    "            \n",
    "            # flip our boxes lr on axis 0\n",
    "            boxes = np.flip(boxes, axis=1)   \n",
    "            \n",
    "            # flip the confidences lr as well\n",
    "            confs = np.flip(confs, axis=1)            \n",
    "        \n",
    "        # small shifts\n",
    "        if random.random() > 0.5:  \n",
    "            ## small random shifts\n",
    "            h_offset = np.random.randint(low=0, high=8)\n",
    "            v_offset = np.random.randint(low=0, high=8)\n",
    "\n",
    "            # crop the images\n",
    "            img = img[v_offset:,h_offset:]\n",
    "        \n",
    "        # level one augmentation\n",
    "        if self.augment >= 1:\n",
    "            # random crop or pad\n",
    "            crop_or_pad = random.random()\n",
    "            \n",
    "            # crop\n",
    "            if crop_or_pad > 0.66:\n",
    "                # crop by max of 16 pixels\n",
    "                h_offset_1 = np.random.randint(low=0, high=30)\n",
    "                v_offset_1 = np.random.randint(low=0, high=30)\n",
    "\n",
    "                h_offset_2 = 1024 - np.random.randint(low=0, high=30)\n",
    "                v_offset_2 = 1024 - np.random.randint(low=0, high=30)\n",
    "\n",
    "                # crop the images\n",
    "                img = img[v_offset_1:v_offset_2,h_offset_1:h_offset_2]\n",
    "\n",
    "                # update the labels - make sure they are positive\n",
    "                boxes[...,0] = np.maximum((boxes[...,0] - (h_offset_1 / CELL_SIZE)), 0.001)\n",
    "                boxes[...,1] = np.maximum((boxes[...,1] - (v_offset_1 / CELL_SIZE)), 0.001)\n",
    "\n",
    "            # pad\n",
    "            elif crop_or_pad > 0.33:\n",
    "                h_offset_1 = np.random.randint(low=0, high=30)\n",
    "                v_offset_1 = np.random.randint(low=0, high=30)\n",
    "\n",
    "                h_offset_2 = np.random.randint(low=0, high=30)\n",
    "                v_offset_2 = np.random.randint(low=0, high=30)\n",
    "\n",
    "                img = np.pad(np.squeeze(img), ((v_offset_1, v_offset_2), (h_offset_1,h_offset_2)), mode=\"constant\", constant_values=0)\n",
    "\n",
    "                # adjust the labels\n",
    "                right_shift = h_offset_2 - h_offset_1\n",
    "                down_shift = v_offset_2 - v_offset_1\n",
    "\n",
    "                boxes[...,0] = np.minimum((boxes[...,0] + (right_shift / CELL_SIZE)), 0.999)\n",
    "                boxes[...,1] = np.minimum((boxes[...,1] + (down_shift / CELL_SIZE)), 0.999)\n",
    "        \n",
    "        # level two augmentation\n",
    "        if self.augment >= 2:\n",
    "            rand_ = random.random()\n",
    "            # multiply\n",
    "            if rand_ > 0.4:  \n",
    "                factor = np.random.uniform(low=0.95, high=1.05)\n",
    "                img = img * factor\n",
    "                \n",
    "            # adjust contrast  \n",
    "            else:\n",
    "                # generate a random contrast adjustment\n",
    "                contrast_factor = np.random.normal(loc=1.0, scale=0.10)\n",
    "\n",
    "                # put some limits on the contrast\n",
    "                contrast_factor = np.minimum(contrast_factor, 1.15)\n",
    "                contrast_factor = np.maximum(contrast_factor, 0.85)\n",
    "\n",
    "                # adjust the image\n",
    "                img = change_contrast(img, contrast_factor)\n",
    "    \n",
    "        # level 3 augmentation\n",
    "        if self.augment >= 3:\n",
    "            # gaussian blur\n",
    "            if random.random() > 0.65:\n",
    "                sigma = np.random.uniform(low=0, high=0.3)\n",
    "                img = gaussian(img, sigma=sigma)\n",
    "        \n",
    "        if self.augment >= 4:\n",
    "            # slight shape skew\n",
    "            if random.random() > 0.75:\n",
    "                x_scale = np.random.uniform(low=0.96, high=1.04, size=None)\n",
    "                y_scale = np.random.uniform(low=0.96, high=1.04, size=None)\n",
    "\n",
    "                # resize the image\n",
    "                img = resize(img, (int(1024 * y_scale), int(1024 * x_scale)), mode='reflect')\n",
    "\n",
    "                # resize the boxes\n",
    "                boxes[...,2] = (boxes[...,2] * x_scale)\n",
    "                boxes[...,3] = (boxes[...,3] * y_scale)\n",
    "        \n",
    "        return img, confs, boxes\n",
    "            \n",
    "            \n",
    "    def __load__(self, filename):\n",
    "        # load dicom file as numpy array\n",
    "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
    "        # get filename without extension\n",
    "        filename = filename.split('.')[0]\n",
    "        label = pneumonia_locations[filename].copy()\n",
    "        \n",
    "        # remove the confidence and bboxes because they will be flipped separately\n",
    "        # don't round the confidence as we are now using the unrounded values\n",
    "        confs = label[:,:,0]\n",
    "        boxes = label[:,:,1:]\n",
    "        \n",
    "        ## augment the data with flips, small shifts and contrast adjustment\n",
    "        img, confs, boxes = self.augment_imgs(img, confs, boxes)\n",
    "            \n",
    "        # resize both image and mask\n",
    "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
    "        \n",
    "        # scale and center the image\n",
    "        img = (img - np.mean(img)) / np.max(img)\n",
    "        \n",
    "        boxes = np.concatenate([confs.reshape((GRID_SIZE,GRID_SIZE,1)), boxes], axis=2)\n",
    "        \n",
    "        # add trailing channel dimension\n",
    "        img = np.expand_dims(img, -1)\n",
    "        return img, boxes\n",
    "    \n",
    "    def __loadpredict__(self, filename):\n",
    "        # load dicom file as numpy array\n",
    "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
    "        # resize image\n",
    "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
    "        # add trailing channel dimension\n",
    "        img = np.expand_dims(img, -1)\n",
    "        return img\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # select batch\n",
    "        filenames = self.filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # predict mode: return images and filenames\n",
    "        if self.predict:\n",
    "            # load files\n",
    "            imgs = [self.__loadpredict__(filename) for filename in filenames]\n",
    "            # create numpy batch\n",
    "            imgs = np.array(imgs)\n",
    "            return imgs, filenames\n",
    "        # train mode: return images and masks\n",
    "        else:\n",
    "            # load files\n",
    "            items = [self.__load__(filename) for filename in filenames]\n",
    "            \n",
    "            # unzip images and masks\n",
    "            imgs, bboxes = zip(*items)\n",
    "            \n",
    "            # create numpy batch\n",
    "            imgs = np.array(imgs)\n",
    "            bboxes = np.array(bboxes)\n",
    "            \n",
    "            # make sure there is at least one positive image in the batch\n",
    "            pos = np.max(bboxes[:,:,:,0])\n",
    "            if pos < 1:\n",
    "                # pick a random positive image\n",
    "                filename = np.random.choice(positive_images)\n",
    "                img, label = self.__load__(filename)\n",
    "                \n",
    "                # add the positive image to our batch\n",
    "                imgs[-1] = img\n",
    "                bboxes[-1] = label\n",
    "                \n",
    "            labels = bboxes\n",
    "            return imgs, labels\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.filenames)\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.predict:\n",
    "            # return everything\n",
    "            return int(np.ceil(len(self.filenames) / self.batch_size))\n",
    "        else:\n",
    "            # return full batches only\n",
    "            return int(len(self.filenames) / self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ijxyGLEwi_-s"
   },
   "source": [
    "### Double Check Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Ts8x9hjhpzK"
   },
   "outputs": [],
   "source": [
    "sample_images = np.random.choice(positive_images, 3)\n",
    "train_gen = generator(folder, sample_images, pneumonia_locations, batch_size=3, image_size=1024, shuffle=True, augment=0, predict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6850
    },
    "colab_type": "code",
    "id": "ssFS91U8hpza",
    "outputId": "b49ebf46-a9f6-4eec-89b7-b2f5cc6cd803",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for imgs, labels in train_gen:\n",
    "    for img, label in zip(imgs, labels):\n",
    "        f, ax = plt.subplots(figsize=(6, 6))\n",
    "        \n",
    "        # display the image\n",
    "        plt.imshow(np.squeeze(img))\n",
    "        print(np.max(img))\n",
    "        \n",
    "        # show the labels\n",
    "        rois = unnorm_label(label)\n",
    "        \n",
    "        for roi in rois:\n",
    "            x, y, w, h, _ = roi\n",
    "            \n",
    "            rect = patches.Rectangle((x,y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    counter += 1\n",
    "    if counter > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_GgDL7ncxT3"
   },
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqobZQZQcxUE"
   },
   "outputs": [],
   "source": [
    "# downsample with max pool\n",
    "def create_downsample(channels, inputs):\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n",
    "    x = keras.layers.LeakyReLU(0.1)(x)\n",
    "    x = keras.layers.MaxPool2D(2)(x)\n",
    "    return x\n",
    "\n",
    "# downsample with conv with stride 2\n",
    "def create_downsample_2(channels, inputs):\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n",
    "    x = keras.layers.LeakyReLU(0.1)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(channels, 3, padding='same', strides=(2,2), use_bias=False)(x)\n",
    "    return x\n",
    "  \n",
    "def create_resblock(channels, inputs):\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n",
    "    x = keras.layers.LeakyReLU(0.1)(x)\n",
    "    \n",
    "    x_1 = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9)(x_1)\n",
    "    x = keras.layers.LeakyReLU(0.1)(x)\n",
    "    \n",
    "    x_2 = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9)(x_2)\n",
    "    x = keras.layers.LeakyReLU(0.1)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
    "    x = keras.layers.LeakyReLU(0.1)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.add([x, x_1])\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
    "    x = keras.layers.LeakyReLU(0.1)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.add([x, x_2])\n",
    "    return x\n",
    "\n",
    "def create_network(input_size, channels, n_blocks=2, depth=4):\n",
    "    # input - 448x448x3\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    \n",
    "    # downsample to 224x224x24\n",
    "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(inputs)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
    "    x = keras.layers.LeakyReLU(0.1)(x)\n",
    "    \n",
    "    # residual blocks\n",
    "    for d in range(depth):\n",
    "        \n",
    "        if d > 0:\n",
    "            x = create_downsample(channels, x)\n",
    "        else:\n",
    "            x = create_downsample_2(channels, x)\n",
    "          \n",
    "        channels = channels * 2\n",
    "        \n",
    "        for b in range(n_blocks):\n",
    "            x = create_resblock(channels, x)\n",
    "    \n",
    "    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
    "    x = keras.layers.LeakyReLU(0)(x)\n",
    "    x = keras.layers.SpatialDropout2D(0.10)(x)\n",
    "    \n",
    "    # dilated conv for context - 14x14x512\n",
    "#     x = keras.layers.Conv2D(512, (3,3), padding='same', activation=None, name=\"dilated_conv_1\")(x)\n",
    "#     x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
    "#     x = keras.layers.LeakyReLU(0.1)(x)\n",
    "#     x = keras.layers.SpatialDropout2D(0.15)(x)\n",
    "   \n",
    "    x = keras.layers.Conv2D(512, (3,3), padding='same', activation=None, name=\"last_conv_1\")(x)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
    "    x = keras.layers.LeakyReLU(0.1)(x)\n",
    "    x = keras.layers.SpatialDropout2D(0.20)(x)\n",
    "\n",
    "    # downsample to 7x7 with stride 2\n",
    "    x = keras.layers.Conv2D(768, (3,3), padding='same', strides=(3,3), activation=None, name=\"downsample_1\", kernel_regularizer=keras.regularizers.l2(l=0.002))(x)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
    "    x = keras.layers.LeakyReLU(0.1)(x)\n",
    "    x = keras.layers.SpatialDropout2D(0.15)(x)\n",
    "    \n",
    "    # confidence output branch\n",
    "    c = keras.layers.Conv2D(1024, (1,1), padding='same', activation=None, name=\"fc_1_c\", kernel_regularizer=keras.regularizers.l2(l=0.01))(x)\n",
    "    c = keras.layers.BatchNormalization(momentum=0.9)(c)\n",
    "    c = keras.layers.LeakyReLU(0.01)(c)\n",
    "    c = keras.layers.SpatialDropout2D(0.15)(c)\n",
    "    \n",
    "    c = keras.layers.Conv2D(512, (1,1), padding='same', activation=None, name=\"fc_2_c\", kernel_regularizer=keras.regularizers.l2(l=0.01))(c)\n",
    "    c = keras.layers.BatchNormalization(momentum=0.9)(c)\n",
    "    c = keras.layers.LeakyReLU(0.01)(c)\n",
    "    c = keras.layers.Dropout(0.10)(c)\n",
    "    \n",
    "    confidence = keras.layers.Conv2D(1, (1,1), padding='same', activation=\"sigmoid\", name=\"confidence_output\")(c)\n",
    "    \n",
    "    # bounding box branch\n",
    "    b = keras.layers.Conv2D(1568, (1,1), padding='same', activation=None, name=\"fc_1_b\", kernel_regularizer=keras.regularizers.l2(l=0.01))(x)\n",
    "    b = keras.layers.BatchNormalization(momentum=0.9)(b)\n",
    "    b = keras.layers.LeakyReLU(0.01)(b)\n",
    "    b = keras.layers.SpatialDropout2D(0.15)(b)\n",
    "    \n",
    "    b = keras.layers.Conv2D(1024, (1,1), padding='same', activation=None, name=\"fc_2_b\", kernel_regularizer=keras.regularizers.l2(l=0.01))(b)\n",
    "    b = keras.layers.BatchNormalization(momentum=0.9)(b)\n",
    "    b = keras.layers.LeakyReLU(0.01)(b)\n",
    "    b = keras.layers.Dropout(0.10)(b)\n",
    "    \n",
    "    boxes = keras.layers.Conv2D(4, (1,1), padding='same', activation=\"sigmoid\")(b)\n",
    "    output = keras.layers.concatenate([confidence, boxes], name=\"bboxes_output\")\n",
    "    \n",
    "    # return both outputs\n",
    "    model = keras.Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AvdSzGI4cxUL"
   },
   "source": [
    "# Train network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Abs2CM3jUyUt"
   },
   "outputs": [],
   "source": [
    "## callbacks\n",
    "class Calc_IOU_CB(keras.callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # only do this every other epoch as it is slow on a CPU\n",
    "        if epoch % 3 == 0:\n",
    "            valid_gen2 = generator(train_dicom_dir, valid_filenames, pneumonia_locations, batch_size=32, image_size=IMAGE_SIZE, shuffle=True, predict=False)\n",
    "            ious = []\n",
    "            tps = 0\n",
    "            fps = 0\n",
    "            fns = 0\n",
    "\n",
    "            counter = 0\n",
    "            for imgs, labels in valid_gen2:\n",
    "                preds = model.predict(imgs)\n",
    "\n",
    "                for pred, label in zip(preds, labels):\n",
    "                    yhat = unnorm_label(pred)\n",
    "                    y_true = unnorm_label(label)\n",
    "\n",
    "                    if len(yhat) or len(y_true):\n",
    "                        iou = calc_iou_better(y_true, yhat)\n",
    "                        ious.append(iou)\n",
    "\n",
    "                # calculate the precision and recall\n",
    "                tp, fp, fn = calc_tps(labels, preds)\n",
    "\n",
    "                tps += tp\n",
    "                fps += fp\n",
    "                fns += fn\n",
    "\n",
    "                counter += 32\n",
    "\n",
    "                # only evaluate half of val set each epoch to speed up training\n",
    "                if counter > len(valid_filenames) / 6:\n",
    "                    break\n",
    "\n",
    "            prec = tps / (tps + fps)\n",
    "            recall = tps / (tps + fns)\n",
    "            f1_score = 2 * (prec * recall) / (prec + recall)\n",
    "            print(\"Epoch\", epoch+1, \": Mean IOU:\", np.mean(ious), \"Precision:\", prec, \"Recall:\", recall, \"F1:\", f1_score)\n",
    "        \n",
    "        return\n",
    "\n",
    "class UploadCheckpointCB(keras.callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):      \n",
    "        if epoch % 2 == 0:\n",
    "            !gsutil cp ./{CHECKPOINT_PATH} gs://{bucket_name}/\n",
    "\n",
    "        return\n",
    "    \n",
    "# count the true pos, false pos and false negatives so we can calculate precision and recall\n",
    "def calc_tps(y_true, y_pred):\n",
    "    true_confs = np.round(y_true[...,0])\n",
    "    pred_confs = np.round(y_pred[...,0])\n",
    "    \n",
    "    tps = np.sum((pred_confs == 1) & (true_confs == 1))\n",
    "    fps = np.sum((pred_confs == 1) & (true_confs != 1))\n",
    "    fns = np.sum((pred_confs != 1) & (true_confs == 1))\n",
    "    \n",
    "    return tps, fps, fns      \n",
    "\n",
    "# exponential learning rate decay\n",
    "def exp_decay(x):\n",
    "    lr0 = 0.01\n",
    "    epochs_drop = 15\n",
    "    drop = 0.75\n",
    "    lrate = lr0 * math.pow(drop, math.floor((1+x)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(CHECKPOINT_PATH, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=True, mode='auto', period=1)\n",
    "learning_rate = tf.keras.callbacks.LearningRateScheduler(exp_decay)\n",
    "catch_nan = tf.keras.callbacks.TerminateOnNaN()  \n",
    "upload_checkpoint = UploadCheckpointCB()  \n",
    "calc_iou = Calc_IOU_CB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCgIz8CwcxUO"
   },
   "outputs": [],
   "source": [
    "## LOSS FUNCTIONS AND METRICS\n",
    "GRID_SIZE = 7\n",
    "CELL_SIZE = 1024 / GRID_SIZE\n",
    "\n",
    "# calculate f1 score with smoothing to avoid NaNs\n",
    "def f1_score(y_true, y_pred):\n",
    "    # apply sigmoid and round our labels\n",
    "    y_pred = tf.round(y_pred[...,0])\n",
    "    y_true = tf.round(y_true[...,0])\n",
    "\n",
    "    # true positives are both pred and truth == 1\n",
    "    tps = tf.reduce_sum(y_pred * y_true) + 1\n",
    "    # false positives are truth == 0 and pred == 1\n",
    "    not_y_true = tf.cast(tf.equal(y_true, 0), dtype=tf.float32)\n",
    "    fps = tf.reduce_sum(y_pred * not_y_true)\n",
    "    # false negatives is truth == 1 and pred == 0a\n",
    "    not_y_pred = tf.cast(tf.equal(y_pred, 0), dtype=tf.float32)\n",
    "    fns = tf.reduce_sum(y_true * not_y_pred)\n",
    "\n",
    "    precision = tps / (tps + fps)\n",
    "    recall = tps / (tps + fns)\n",
    "\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return f1_score\n",
    "\n",
    "def binary_accuracy(y_true, y_pred):\n",
    "    # apply sigmoid to our predictions and round to 0 or 1\n",
    "    y_pred = tf.round(y_pred)\n",
    "    y_true = tf.round(y_true)\n",
    "    \n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(y_true[...,0], y_pred[...,0]), dtype=tf.float32))\n",
    "    return acc\n",
    "\n",
    "def overlap_iou(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        bboxes1: shape (batch_size, 16, 16, 4)\n",
    "            with x1, y1, x2, y2 point order.\n",
    "        bboxes2: shape (batch_size, 16, 16, 4)\n",
    "            with x1, y1, x2, y2 point order.\n",
    "        p1 *-----\n",
    "           |     |\n",
    "           |_____* p2\n",
    "    Returns:\n",
    "        Tensor with shape (total_bboxes1, total_bboxes2)\n",
    "        with the IoU (intersection over union) of bboxes1[i] and bboxes2[j]\n",
    "        in [i, j].\n",
    "    \"\"\"\n",
    "    \n",
    "    # flatten the data because it's easier that way\n",
    "    bboxes1 = tf.reshape(y_true, (-1, 5))\n",
    "    bboxes2 = tf.reshape(y_pred, (-1, 5))\n",
    "    \n",
    "    # split the components out\n",
    "    true_boxes, x11, y11, w1, h1 = tf.split(bboxes1, 5, axis=1)\n",
    "    pred_conf, x21, y21, w2, h2 = tf.split(bboxes2, 5, axis=1)\n",
    "    \n",
    "    # make sure the truth is an int\n",
    "    true_boxes = tf.round(true_boxes)\n",
    "    \n",
    "    # convert the sigmoid output to center coordinates\n",
    "    # add some to avoid negative numbers\n",
    "    x11 = (x11 * CELL_SIZE) + 512\n",
    "    x21 = (x21 * CELL_SIZE) + 512\n",
    "    y11 = (y11 * CELL_SIZE) + 512\n",
    "    y21 = (y21 * CELL_SIZE) + 512\n",
    "    \n",
    "    # get the actual height and width numbers\n",
    "    w1 = w1 * 1024\n",
    "    w2 = w2 * 1024\n",
    "    h1 = h1 * 1024\n",
    "    h2 = h2 * 1024\n",
    "    \n",
    "    # only count the cell is there is actually an ROI here or if one is predicted\n",
    "    mask = (pred_conf >= 0.5) | (tf.round(true_boxes) == 1)\n",
    "    \n",
    "    # get the far corners of the boxes\n",
    "    x12 = x11 + (w1 / 2)\n",
    "    y12 = y11 + (h1 / 2)\n",
    "    x22 = x21 + (w2 / 2)\n",
    "    y22 = y21 + (h2 / 2)\n",
    "    \n",
    "    x11 = x11 - (w1 / 2)\n",
    "    y11 = y11 - (h1 / 2)\n",
    "    x21 = x21 - (w2 / 2)\n",
    "    y21 = y21 - (h2 / 2)\n",
    "\n",
    "    # find the corners of the intersection area\n",
    "    xI1 = tf.maximum(x11, x21)\n",
    "    yI1 = tf.maximum(y11, y21)\n",
    "\n",
    "    xI2 = tf.minimum(x12, x22)\n",
    "    yI2 = tf.minimum(y12, y22)\n",
    "    \n",
    "    # get the intersection area, if the truth has no boxes it is 0\n",
    "    inter_area = true_boxes * (xI2 - xI1) * (yI2 - yI1)\n",
    "\n",
    "    # get the area of each box\n",
    "    bboxes1_area = (w1) * (h1)\n",
    "    bboxes2_area = (w2) * (h2)\n",
    "    \n",
    "    # union is area of both boxes - intersection\n",
    "    union = (bboxes1_area + bboxes2_area) - inter_area\n",
    "    \n",
    "    iou = tf.maximum(inter_area/(union + 1e-6), 0)\n",
    "    \n",
    "    # apply the mask\n",
    "    iou = iou * tf.cast(mask, dtype=tf.float32)\n",
    "    \n",
    "    # reduce the mean so we have mean iou for our inputs\n",
    "    return tf.reduce_mean(iou)\n",
    "                    \n",
    "def loss_fn(y_true, y_pred):  \n",
    "    # get the xe loss\n",
    "    xe_loss = binary_cross_entropy(y_true, y_pred)\n",
    "    \n",
    "    # get the box loss\n",
    "    box_loss = adj_mse(y_true, y_pred)\n",
    "    \n",
    "    # add the losses and return them\n",
    "    return (1.0 * xe_loss) + (box_loss * 10.0)\n",
    "\n",
    "def adj_mse(y_true, y_pred):    \n",
    "    # square the error\n",
    "    square_error = tf.square(y_true[...,1:] - y_pred[...,1:])\n",
    "    sse = tf.reduce_sum(square_error, axis=[3])\n",
    "    \n",
    "    # apply the mask so we only count the loss from cells with actual ROIs\n",
    "    mask = y_true[...,0]\n",
    "    \n",
    "    sse = tf.multiply(sse, mask)\n",
    "    \n",
    "    loss = tf.reduce_sum(sse)            \n",
    "            \n",
    "    return loss  \n",
    "  \n",
    "# use weight of 0.5 for negative cells, 19 for positive ones\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    conf_true = tf.round(y_true[...,0])\n",
    "    conf_pred = y_pred[...,0]\n",
    "    \n",
    "    weight = 5.0\n",
    "    weights = tf.multiply(conf_true, weight) + 0.5\n",
    "    \n",
    "    xe = tf.multiply(tf.square(conf_true - conf_pred), weights)\n",
    "    \n",
    "    return tf.reduce_sum(xe)\n",
    "\n",
    "def objectness_loss_fn(y_true, y_pred):\n",
    "    \n",
    "    # pred box conf\n",
    "    pred_box_conf = y_pred[...,0]\n",
    "    \n",
    "    # separate the x, y from the w, h\n",
    "    true_box_xy = y_true[...,1:3] * CELL_SIZE\n",
    "    true_box_wh = y_true[...,3:] * 1024\n",
    "    \n",
    "    pred_box_xy = y_pred[...,1:3] * CELL_SIZE\n",
    "    pred_box_wh = y_pred[...,3:] * 1024\n",
    "    \n",
    "    # get the corners of the boxes by subtracting or adding half of h, w\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "    \n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half  \n",
    "    \n",
    "    # get the corners of the intersect area\n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas + 1e-16)\n",
    "    \n",
    "    true_box_conf = iou_scores * y_true[..., 0]\n",
    "    \n",
    "    conf_mask  = tf.zeros_like(iou_scores)\n",
    "    conf_mask = conf_mask + tf.cast((iou_scores < 0.6), dtype=tf.float32) * (1 - y_true[...,0])\n",
    "    conf_mask = conf_mask + y_true[..., 0] * 5.0\n",
    "    \n",
    "    nb_conf_box  = tf.reduce_sum(tf.cast((conf_mask > 0.0), dtype=tf.float32)) \n",
    "    \n",
    "    loss_conf  =  tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box + 1e-6) / 2.\n",
    "    \n",
    "    return tf.reduce_sum(loss_conf)\n",
    "\n",
    "def iou_loss_fn(y_true, y_pred):\n",
    "    \n",
    "    # separate the x, y from the w, h and unnormalize them\n",
    "    true_box_xy = y_true[...,1:3] * CELL_SIZE\n",
    "    true_box_wh = y_true[...,3:] * 1024\n",
    "    \n",
    "    pred_box_xy = y_pred[...,1:3] * CELL_SIZE\n",
    "    pred_box_wh = y_pred[...,3:] * 1024\n",
    "    \n",
    "    # get the corners of the boxes by subtracting or adding half of h, w\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "    \n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half  \n",
    "    \n",
    "    # get the corners of the intersect area\n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    # get the area of the boxes\n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    # calculate the IOU\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    # multiple the IOU by the confidence so we have a more useful loss function\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas + 1e-16) * y_pred[...,0]\n",
    "    \n",
    "    # only use the IOU from boxes which actually have ROIs\n",
    "    mask = y_true[...,0]\n",
    "    \n",
    "    # subtract IOU from 1 and apply the mask\n",
    "    use_iou = (1 - iou_scores)\n",
    "    use_iou = tf.multiply(use_iou, mask)\n",
    "    \n",
    "    return tf.reduce_sum(use_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4673
    },
    "colab_type": "code",
    "id": "-Kp-kddyJm2P",
    "outputId": "8ac36a4e-5d6e-4ea1-afd0-83e3779dadd8"
   },
   "outputs": [],
   "source": [
    "model = create_network(input_size=IMAGE_SIZE, channels=32, n_blocks=1, depth=4)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.008, beta_1=0.9, beta_2=0.999, decay=0.0, clipnorm=1.0, clipvalue=0.5)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_fn,\n",
    "              metrics=[binary_accuracy, adj_mse, binary_cross_entropy, overlap_iou, f1_score])\n",
    "\n",
    "model.load_weights(CHECKPOINT_PATH)\n",
    "\n",
    "use_tpu = True\n",
    "# if we are using the tpu copy the keras model to a new var and assign the tpu model to model\n",
    "if use_tpu:\n",
    "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "    \n",
    "    # create network and compiler\n",
    "    tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
    "        model, strategy = tf.contrib.tpu.TPUDistributionStrategy(\n",
    "            tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
    "    \n",
    "    BATCH_SIZE = BATCH_SIZE * 8\n",
    "    \n",
    "# create train and validation generators\n",
    "folder = './stage_1_train_images'\n",
    "\n",
    "# generators add augmentation with 1 having none and 4 having full augmentation. \n",
    "# generator 5 trains on all files, not separating out validation set to be used for final epochs\n",
    "train_gen_1 = generator(folder, train_filenames, pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=0, predict=False)\n",
    "train_gen_2 = generator(folder, train_filenames, pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=1, predict=False)\n",
    "train_gen_3 = generator(folder, train_filenames, pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=2, predict=False)\n",
    "train_gen_4 = generator(folder, train_filenames, pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=3, predict=False)\n",
    "train_gen_5 = generator(folder, train_filenames, pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=4, predict=False)\n",
    "train_gen_6 = generator(folder, filenames, pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=4, predict=False)\n",
    "train_gen = generator(folder, train_filenames, pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=True, predict=False)\n",
    "\n",
    "valid_gen = generator(folder, valid_filenames, pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=False, predict=False)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7353
    },
    "colab_type": "code",
    "id": "fM5VeiuDcxUY",
    "outputId": "9eb8ab6b-f3cb-47ce-ea9e-76c3dcae6e2a"
   },
   "outputs": [],
   "source": [
    "history = tpu_model.fit_generator(train_gen_1, validation_data=valid_gen, callbacks=[learning_rate, catch_nan, checkpoint, upload_checkpoint], epochs=20, shuffle=True, verbose=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6925
    },
    "colab_type": "code",
    "id": "7tyG7P79Y42U",
    "outputId": "9f7d37a1-9a07-484f-888c-ff8954c331b1"
   },
   "outputs": [],
   "source": [
    "history = tpu_model.fit_generator(train_gen_2, validation_data=valid_gen, callbacks=[learning_rate, catch_nan, checkpoint, upload_checkpoint], epochs=40, shuffle=True, verbose=1, initial_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8042
    },
    "colab_type": "code",
    "id": "MRunr7Vdj2KJ",
    "outputId": "b135fe6c-fa64-4a5a-e0cc-ae9e921bd330"
   },
   "outputs": [],
   "source": [
    "history = tpu_model.fit_generator(train_gen_3, validation_data=valid_gen, callbacks=[learning_rate, catch_nan, checkpoint, upload_checkpoint], epochs=60, shuffle=True, verbose=1, initial_epoch=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "colab_type": "code",
    "id": "q_6ZHP5VWDHz",
    "outputId": "970b9bc1-9c3c-42e7-e621-ccd5aa788663"
   },
   "outputs": [],
   "source": [
    "history = tpu_model.fit_generator(train_gen_3, validation_data=valid_gen, callbacks=[learning_rate, catch_nan, checkpoint, upload_checkpoint], epochs=90, shuffle=True, verbose=1, initial_epoch=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejsS4X3dWQ0V"
   },
   "outputs": [],
   "source": [
    "history = tpu_model.fit_generator(train_gen_4, validation_data=valid_gen, callbacks=[learning_rate, catch_nan, checkpoint, upload_checkpoint], epochs=110, shuffle=True, verbose=1, initial_epoch=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "id": "y_bLpJPBcxUh",
    "outputId": "f8102e78-2748-4e09-cbde-c8c899408175"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(151)\n",
    "plt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"], label=\"Valid loss\")\n",
    "plt.legend()\n",
    "plt.subplot(152)\n",
    "plt.plot(history.epoch, history.history[\"adj_mse\"], label=\"Train MSE loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_adj_mse\"], label=\"Valid MSE loss\")\n",
    "plt.legend()\n",
    "plt.subplot(153)\n",
    "plt.plot(history.epoch, history.history[\"binary_accuracy\"], label=\"Train Confidence accuracy\")\n",
    "plt.plot(history.epoch, history.history[\"val_binary_accuracy\"], label=\"Valid Confidence accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(154)\n",
    "plt.plot(history.epoch, history.history[\"overlap_iou\"], label=\"Train iou\")\n",
    "plt.plot(history.epoch, history.history[\"val_overlap_iou\"], label=\"Valid iou\")\n",
    "plt.legend()\n",
    "plt.subplot(155)\n",
    "plt.plot(history.epoch, history.history[\"f1_score\"], label=\"Train F1\")\n",
    "plt.plot(history.epoch, history.history[\"val_f1_score\"], label=\"Valid F1\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "colab_type": "code",
    "id": "NIdDp8YOxevU",
    "outputId": "59238e5d-36af-4547-c122-0713cdc87ed8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(151)\n",
    "plt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"], label=\"Valid loss\")\n",
    "plt.legend()\n",
    "plt.subplot(152)\n",
    "plt.plot(history.epoch, history.history[\"adj_mse\"], label=\"Train MSE loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_adj_mse\"], label=\"Valid MSE loss\")\n",
    "plt.legend()\n",
    "plt.subplot(153)\n",
    "plt.plot(history.epoch, history.history[\"binary_accuracy\"], label=\"Train Confidence accuracy\")\n",
    "plt.plot(history.epoch, history.history[\"val_binary_accuracy\"], label=\"Valid Confidence accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(154)\n",
    "plt.plot(history.epoch, history.history[\"overlap_iou\"], label=\"Train iou loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_overlap_iou\"], label=\"Valid iou loss\")\n",
    "plt.legend()\n",
    "plt.subplot(155)\n",
    "plt.plot(history.epoch, history.history[\"f1_score\"], label=\"Train F1\")\n",
    "plt.plot(history.epoch, history.history[\"val_f1_score\"], label=\"Valid F1\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "VFN2BZwIPBVL",
    "outputId": "69a009cd-60cd-4652-d0af-60e15a8e139b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(151)\n",
    "plt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"], label=\"Valid loss\")\n",
    "plt.legend()\n",
    "plt.subplot(152)\n",
    "plt.plot(history.epoch, history.history[\"adj_mse\"], label=\"Train MSE loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_adj_mse\"], label=\"Valid MSE loss\")\n",
    "plt.legend()\n",
    "plt.subplot(153)\n",
    "plt.plot(history.epoch, history.history[\"binary_accuracy\"], label=\"Train Confidence accuracy\")\n",
    "plt.plot(history.epoch, history.history[\"val_binary_accuracy\"], label=\"Valid Confidence accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(154)\n",
    "plt.plot(history.epoch, history.history[\"overlap_iou\"], label=\"Train iou loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_overlap_iou\"], label=\"Valid iou loss\")\n",
    "plt.legend()\n",
    "plt.subplot(155)\n",
    "plt.plot(history.epoch, history.history[\"f1_score\"], label=\"Train F1\")\n",
    "plt.plot(history.epoch, history.history[\"val_f1_score\"], label=\"Valid F1\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "colab_type": "code",
    "id": "Jr9ml4dR92hf",
    "outputId": "e8c4262b-2b29-4dfc-fb0e-0554bd65296c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(151)\n",
    "plt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"], label=\"Valid loss\")\n",
    "plt.legend()\n",
    "plt.subplot(152)\n",
    "plt.plot(history.epoch, history.history[\"adj_mse\"], label=\"Train MSE loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_adj_mse\"], label=\"Valid MSE loss\")\n",
    "plt.legend()\n",
    "plt.subplot(153)\n",
    "plt.plot(history.epoch, history.history[\"binary_accuracy\"], label=\"Train Confidence accuracy\")\n",
    "plt.plot(history.epoch, history.history[\"val_binary_accuracy\"], label=\"Valid Confidence accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(154)\n",
    "plt.plot(history.epoch, history.history[\"iou_loss_fn\"], label=\"Train iou loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_iou_loss_fn\"], label=\"Valid iou loss\")\n",
    "plt.legend()\n",
    "plt.subplot(155)\n",
    "plt.plot(history.epoch, history.history[\"f1_score\"], label=\"Train F1\")\n",
    "plt.plot(history.epoch, history.history[\"val_f1_score\"], label=\"Valid F1\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dpxfbugzcLT"
   },
   "source": [
    "## Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UI8pvQ2e_kgw"
   },
   "outputs": [],
   "source": [
    "model.load_weights(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 11515
    },
    "colab_type": "code",
    "id": "A03zhJyfUyV2",
    "outputId": "9b128ec0-28be-45b2-de44-fbf379005dd3"
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.6\n",
    "OVERLAP = 0.3\n",
    "# look at some sample predictions\n",
    "samples = np.random.choice(valid_filenames, size=20, replace=False)\n",
    "# samples = problem_names\n",
    "\n",
    "coords = np.arange(0, 1024, CELL_SIZE)\n",
    "overall_ious = []\n",
    "map_ious = []\n",
    "\n",
    "for filename in samples:\n",
    "    # load the image\n",
    "    img = pydicom.dcmread(os.path.join(train_dicom_dir, filename)).pixel_array\n",
    "    \n",
    "    filename = filename.split('.')[0]\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    # initialize our lists\n",
    "    ious = []\n",
    "    truths = []\n",
    "    boxes = []\n",
    "    \n",
    "    # draw the truth boxes\n",
    "    if filename in pneumonia_locations:\n",
    "        locs = pneumonia_locations[filename].copy()\n",
    "        for i in range(GRID_SIZE):\n",
    "            for j in range(GRID_SIZE):\n",
    "                pixel_data = locs[i,j,:]\n",
    "                if pixel_data[0] > 0.5:\n",
    "                    x, y, w, h = pixel_data[1:]\n",
    "                    \n",
    "                    # unnormalize the data\n",
    "                    w = w * 1024\n",
    "                    h = h * 1024\n",
    "                    \n",
    "                    x = unnorm(x, j, CELL_SIZE)\n",
    "                    y = unnorm(y, i, CELL_SIZE)\n",
    "                    \n",
    "                    # get the corners\n",
    "                    x = x - (w // 2)\n",
    "                    y = y - (h // 2)\n",
    "                    \n",
    "                    x = int(x)\n",
    "                    y = int(y)\n",
    "                    w = int(w)\n",
    "                    h = int(h)\n",
    "                    locs[i,j,:] = [1, x, y, w, h]\n",
    "                    print(\"Truth:\", i, j, x, y, w, h)\n",
    "                    truths.append([x, y, w, h])\n",
    "                    \n",
    "                    rect = patches.Rectangle((x,y),w,h,linewidth=1,edgecolor='b',facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "                    \n",
    "    # predict the image\n",
    "    img = resize(img, (IMAGE_SIZE, IMAGE_SIZE), mode='reflect')\n",
    "    yhat = model.predict(img.reshape(1, IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    conf = np.squeeze(yhat)[:,:,0]\n",
    "    bboxes = np.squeeze(yhat)[:,:,1:]    \n",
    "    pred_boxes = np.zeros_like(bboxes)\n",
    "  \n",
    "    # print the confidences for our true boxes, if any\n",
    "    mask = (locs[...,0] > 0.5)\n",
    "    \n",
    "    # loop through our predictions\n",
    "    for i in range(GRID_SIZE):\n",
    "        for j in range(GRID_SIZE):\n",
    "            conf_ = conf[i,j]\n",
    "            # if we have a prediction\n",
    "            if conf_ > THRESHOLD:\n",
    "                x,y,w,h = bboxes[i,j,:]\n",
    "                \n",
    "                # unnormalize the data\n",
    "                w = w * 1024\n",
    "                h = h * 1024\n",
    "\n",
    "                x = unnorm(x, j, CELL_SIZE)\n",
    "                y = unnorm(y, i, CELL_SIZE)\n",
    "                \n",
    "                # convert to upper left corner from center\n",
    "                x = np.maximum(x - (w // 2), 0)\n",
    "                y = np.maximum(y - (h // 2), 0)\n",
    "                \n",
    "                x = int(x)\n",
    "                y = int(y)\n",
    "                w = int(w)\n",
    "                h = int(h)\n",
    "                \n",
    "                pred_boxes[i,j,:] = [x, y, w, h]\n",
    "                \n",
    "                print(\"Pred:\", i, j, \"conf:\", conf_, x, y, w, h)\n",
    "                \n",
    "                # if the boxes have width and height add them to our list\n",
    "                if w > 30 and h > 30:\n",
    "                    boxes.append([x,y,w,h, conf_])\n",
    "            elif mask[i,j]:\n",
    "              print(\"False Negative:\", i, j, \"conf:\", conf_)\n",
    "              \n",
    "    ## if we have ground truths OR predictions calculate the IOUs:\n",
    "    if len(boxes) or len(truths):\n",
    "        # do non-max suppression of our boxes\n",
    "        nms_boxes = non_max_suppression_fast(np.array(boxes), OVERLAP)\n",
    "\n",
    "        # only count the IOU if there are either ground truths or predictions\n",
    "        if len(nms_boxes) or len(truths):\n",
    "            iou = calc_iou_better(np.array(truths), np.array(nms_boxes))\n",
    "            print(\"IOU post-nms:\", iou)\n",
    "            overall_ious.append(iou)\n",
    "\n",
    "        # plot our boxes\n",
    "        for box in nms_boxes:\n",
    "            x,y,w,h,c = box\n",
    "            rect = patches.Rectangle((x,y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        if len(nms_boxes):\n",
    "            scores = nms_boxes[...,4]\n",
    "        else:\n",
    "            scores = np.array([])\n",
    "\n",
    "        map_iou_score = map_iou(np.array(truths), np.array(nms_boxes), scores)\n",
    "\n",
    "        if map_iou_score is not None:\n",
    "            map_ious.append(map_iou_score)\n",
    "\n",
    "        for item in coords:\n",
    "            plt.axvline(item, linewidth=0.5)\n",
    "            plt.axhline(item, linewidth=0.5)\n",
    "\n",
    "        print(\"IOU:\", iou)\n",
    "        print(\"Map IOU:\", map_iou_score)\n",
    "    \n",
    "    plt.title(filename)\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Overall Mean IOU:\", np.mean(overall_ious))    \n",
    "print(\"Overall Map IOU:\", np.mean(map_ious))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQrvPBiFa9GM"
   },
   "source": [
    "## Threshold Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6ydkB2Sa-x9"
   },
   "outputs": [],
   "source": [
    "def scores_at_threshold(y_true, y_pred, thresholds=[0.5, 0.55, 0.6,0.65, 0.7,0.75, 0.8, 0.85, 0.9]):\n",
    "    prec_scores = []\n",
    "    rec_scores = []\n",
    "    iou_scores = []\n",
    "    accuracy_scores = []\n",
    "    \n",
    "    # calculate the scores\n",
    "    for threshold in thresholds:\n",
    "        # extract the prediction from the input\n",
    "        pred_true = (y_pred[...,0] > threshold) * 1.0\n",
    "        gt_true = np.round(y_true[...,0])\n",
    "\n",
    "        # calculate the prec, rec, accuracy\n",
    "        accuracy = np.mean((pred_true == gt_true) * 1.0)\n",
    "        \n",
    "        tp = np.sum(pred_true * gt_true)\n",
    "        fp = np.sum(pred_true * (gt_true == 0))\n",
    "        fn = np.sum(gt_true * (pred_true == 0))\n",
    "        \n",
    "        # if there are true ROIs and predictions\n",
    "        if (np.sum(gt_true) > 0) and (np.sum(pred_true) > 0):\n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "        # else if there are no truths but there are preds it is 0\n",
    "        elif (np.sum(gt_true) == 0) and (np.sum(pred_true) > 0):\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "        # else if both are 0 we predicted all correctly\n",
    "        else:\n",
    "            precision = 1\n",
    "            recall = 1\n",
    "        \n",
    "        accuracy_scores.append(accuracy)\n",
    "        prec_scores.append(precision)\n",
    "        rec_scores.append(recall)\n",
    "        \n",
    "        temp_ious = []\n",
    "        # calculate the IOU\n",
    "        for gt_, yhat_ in zip(y_true, y_pred):\n",
    "            # if there are true ROIs calculate the ROI\n",
    "            gt_rois = unnorm_label(np.squeeze(gt_), threshold)\n",
    "            pred_rois = unnorm_label(np.squeeze(yhat_), threshold)\n",
    "\n",
    "            iou = calc_iou_better(gt_rois, pred_rois)\n",
    "            temp_ious.append(iou)\n",
    "\n",
    "        iou_scores.append(np.mean(temp_ious))\n",
    "        \n",
    "    return prec_scores, rec_scores, iou_scores, accuracy_scores, thresholds\n",
    "\n",
    "def plot_thresholds(thresholds=[0.5, 0.55, 0.6,0.65, 0.7,0.75, 0.8, 0.85, 0.9], iterations=30):\n",
    "    precs = np.zeros_like(thresholds)\n",
    "    recs = np.zeros_like(thresholds)\n",
    "    ious = np.zeros_like(thresholds)\n",
    "    accs = np.zeros_like(thresholds)\n",
    "\n",
    "    counter = 0\n",
    "    for imgs, labels in valid_gen:\n",
    "        preds = model.predict(imgs)\n",
    "        prec, rec, iou, acc, th = scores_at_threshold(labels, preds, thresholds)\n",
    "        precs += np.array(prec)\n",
    "        recs += np.array(rec)\n",
    "        ious += np.array(iou)\n",
    "        accs += np.array(acc)\n",
    "\n",
    "        counter += 1\n",
    "        if counter > iterations:\n",
    "            precs /= counter\n",
    "            recs /= counter\n",
    "            ious /= counter\n",
    "            accs /= counter\n",
    "            break\n",
    "            \n",
    "    plt.plot(thresholds, ious, color=\"red\", label=\"IOU\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(thresholds, recs, color=\"red\", label=\"Recall\")\n",
    "    plt.plot(thresholds, precs, color=\"green\", label=\"Precision\")\n",
    "    plt.plot(thresholds, accs, color=\"blue\", label=\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "id": "3uHxQtTqa_NB",
    "outputId": "64f122cb-f1ea-472d-92aa-878fcfa816b4"
   },
   "outputs": [],
   "source": [
    "plot_thresholds([0.5, 0.55, 0.6,0.65, 0.7,0.75, 0.8, 0.85, 0.9], iterations=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tAntxescxUq"
   },
   "source": [
    "# Predict test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fnu7ebfScxUu"
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.7\n",
    "\n",
    "# load and shuffle filenames\n",
    "folder = './stage_1_test_images'\n",
    "test_filenames = os.listdir(folder)\n",
    "print('n test samples:', len(test_filenames))\n",
    "\n",
    "# create test generator with predict flag set to True\n",
    "test_gen = generator(folder, test_filenames, None, batch_size=24, image_size=IMAGE_SIZE, shuffle=False, predict=True)\n",
    "\n",
    "# create submission dictionary\n",
    "submission_dict = {}\n",
    "# loop through testset\n",
    "for imgs, filenames in test_gen:\n",
    "    \n",
    "    # predict batch of images\n",
    "    yhats = model.predict(imgs)\n",
    "    \n",
    "    # loop through batch\n",
    "    for yhat, filename in zip(yhats, filenames):\n",
    "        predictionString = \"\"\n",
    "        boxes = []\n",
    "        for i in range(GRID_SIZE):\n",
    "            for j in range(GRID_SIZE):\n",
    "                conf = yhat[i, j, 0]\n",
    "                if conf > THRESHOLD:\n",
    "                    x, y, w, h = yhat[i,j, 1:]\n",
    "                    \n",
    "                    # possible thresholds to keep our boxes within reasonable sizes?\n",
    "                    if True: #w < 600 and h < 1000:\n",
    "                        w = w * 1024\n",
    "                        h = h * 1024\n",
    "\n",
    "                        x = unnorm(x, j, CELL_SIZE)\n",
    "                        y = unnorm(y, i, CELL_SIZE)\n",
    "\n",
    "                        # convert to upper left corner from center\n",
    "                        x = x - (w // 2)\n",
    "                        y = y - (h // 2)\n",
    "                        \n",
    "                        if w > 20 and h > 20:\n",
    "                            # make sure our boxes don't run off the edges of the images\n",
    "                            w = np.minimum(w, 1024 - x)\n",
    "                            h = np.minimum(h, 1024 - y)\n",
    "                            boxes.append([x,y,w,h])\n",
    "\n",
    "        # do our non-max suppression here\n",
    "        boxes = non_max_suppression_fast(np.array(boxes), 0.3)\n",
    "        \n",
    "        # loop through our suppressed boxes and creat the prediction string\n",
    "        for box in boxes:\n",
    "            x,y,w,h = box\n",
    "            \n",
    "            x = int(x)\n",
    "            y = int(y)\n",
    "            w = int(w)\n",
    "            h = int(h)\n",
    "        \n",
    "            # create the prediction string\n",
    "            predictionString += str(0.9) + ' ' + str(x) + ' ' + str(y) + ' ' + str(w) + ' ' + str(h) + ' '\n",
    "            \n",
    "        # add filename and predictionString to dictionary\n",
    "        filename = filename.split('.')[0]\n",
    "        submission_dict[filename] = predictionString\n",
    "\n",
    "    # stop if we've got them all\n",
    "    if len(submission_dict) >= len(test_filenames):\n",
    "        break\n",
    "    \n",
    "# save dictionary as csv file\n",
    "sub = pd.DataFrame.from_dict(submission_dict,orient='index')\n",
    "sub.index.names = ['patientId']\n",
    "sub.columns = ['PredictionString']\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "today = str(now)[:10]\n",
    "submission_file = today + \"_yolo_submission.csv\" \n",
    "sub.to_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1NEg9QCcxU4"
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c rsna-pneumonia-detection-challenge -f {submission_file} -m \"YOLOv25.1 448x448 60 epochs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yf06y04TVRi2"
   },
   "outputs": [],
   "source": [
    "# upload checkpoint to GCS\n",
    "project_id = 'mammography-198911'\n",
    "bucket_name = 'pneumonia'\n",
    "\n",
    "!gcloud config set project {project_id}\n",
    "!gsutil cp ./{CHECKPOINT_PATH} gs://{bucket_name}/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "yolo_448X448_25.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
